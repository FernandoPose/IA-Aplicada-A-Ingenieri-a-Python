{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Brain Tumor MRI Dataset\n",
        "\n",
        "\n",
        "### What is a brain tumor?\n",
        "\n",
        "A brain tumor is a collection, or mass, of abnormal cells in your brain. Your skull, which encloses your brain, is very rigid. Any growth inside such a restricted space can cause problems. Brain tumors can be cancerous (malignant) or noncancerous (benign). When benign or malignant tumors grow, they can cause the pressure inside your skull to increase. This can cause brain damage, and it can be life-threatening.\n",
        "\n",
        "\n",
        "### The importance of the subject\n",
        "\n",
        "Early detection and classification of brain tumors is an important research domain in the field of medical imaging and accordingly helps in selecting the most convenient treatment method to save patients life therefore\n",
        "\n",
        "\n",
        "### About Dataset\n",
        "\n",
        "El conjunto de datos contiene 3064 imágenes potenciadas con contraste potenciadas en T1 de 233 pacientes con tres tipos de tumores cerebrales:\n",
        "\n",
        "*   meningioma (708 cortes)\n",
        "*   glioma (1426 cortes)\n",
        "*   pituitario (930 cortes)\n",
        "\n",
        "Each image is of dimension 512 x 512 x 1 , these are black and white images thus having a single channel.\n",
        "\n",
        "Download link: https://figshare.com/articles/dataset/brain_tumor_dataset/1512427\n",
        "\n",
        "\n",
        "\n",
        "### Author\n",
        "\n",
        "Jun Cheng\n",
        "School of Biomedical Engineering\n",
        "Southern Medical University, Guangzhou, China\n",
        "Email: chengjun583@qq.com"
      ],
      "metadata": {
        "id": "xg8ZSn10m3kM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "YtCPlrywsEfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip dataset\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "# Extract images\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Download images\n",
        "import requests\n",
        "import argparse\n",
        "\n",
        "# Ordeno imagenes\n",
        "import shutil"
      ],
      "metadata": {
        "id": "QGd7nc3dq1fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_screen():\n",
        "    \"\"\"Clears the console screen irrespective of os used\"\"\"\n",
        "    import platform\n",
        "    if platform.system() == 'Windows':\n",
        "        os.system('cls')\n",
        "        return\n",
        "    os.system('clear')\n",
        "\n",
        "def make_folder(target_folder):\n",
        "    \"\"\"Creates folder if there is no folder in the specified path.\n",
        "    Parameters:\n",
        "        target_folder(str): path of the folder which needs to be created.\n",
        "\n",
        "    Returns: None\n",
        "    \"\"\"\n",
        "    if not (os.path.isdir(target_folder)):\n",
        "        print(f'Creating {target_folder} folder')\n",
        "        os.mkdir(target_folder)\n",
        "\n",
        "def check_if_file_exits(file):\n",
        "    \"\"\" Checks if the file specified is downloaded or not.\n",
        "    Parameters:\n",
        "        file(str): Name of the file to be checked.\n",
        "\n",
        "    Returns: None\n",
        "    \"\"\"\n",
        "    extension = file[-3:]\n",
        "    file = file[:-4] + '_done.'+extension\n",
        "    return True if os.path.isfile(file) else False"
      ],
      "metadata": {
        "id": "6eGS8san056J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, path):\n",
        "    \"\"\" Download the file in url to the path specified.\n",
        "    Parameters:\n",
        "        url(str): URL of the file to be downloaded.\n",
        "        path(str): Destination where the downloaded file will be saved.\n",
        "\n",
        "    Returns: None\n",
        "    \"\"\"\n",
        "    # Check if file already exists.\n",
        "    if check_if_file_exits(path):\n",
        "        print(f'Already existing file {path}')\n",
        "        return\n",
        "\n",
        "    # Deleting the partial downloaded file.\n",
        "    if os.path.isfile(path):\n",
        "        print(f'Deleted existing partial file {path}')\n",
        "        os.remove(path)\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    handle = open(path, \"wb\")\n",
        "    with open(path, \"wb\") as handle:\n",
        "        chunk_size = 1024\n",
        "        total_size = round(int(response.headers['Content-Length']), 3)\n",
        "        pbar = tqdm(unit=\"B\", total=total_size)\n",
        "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "            if chunk:  # filter out keep-alive new chunks\n",
        "                handle.write(chunk)\n",
        "                pbar.update(len(chunk))\n",
        "\n",
        "    # Marking the file as downloaded.\n",
        "    extension = path[-3:]\n",
        "    os.rename(path, path[:-4]+'_done.'+extension)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # URL of the dataset used.\n",
        "    dataset_urls = ['https://ndownloader.figshare.com/files/3381290',\n",
        "                    'https://ndownloader.figshare.com/files/3381296',\n",
        "                    'https://ndownloader.figshare.com/files/3381293',\n",
        "                    'https://ndownloader.figshare.com/files/3381302']\n",
        "\n",
        "    # URL of dataset README\n",
        "    dataset_readme = 'https://ndownloader.figshare.com/files/7953679'\n",
        "\n",
        "    target_folder = 'dataset'\n",
        "    dataset_part = 1\n",
        "    dataset_file_name = f'brain_tumor_dataset_part_'\n",
        "\n",
        "    clear_screen()\n",
        "    make_folder(target_folder)\n",
        "\n",
        "    print(f'\\n\\tDownloading dataset README.txt')\n",
        "    download_file(dataset_readme, os.path.join(target_folder, 'README.TXT'))\n",
        "\n",
        "    print('\\n\\tStarting download process\\n')\n",
        "    for url in dataset_urls:\n",
        "        try:\n",
        "            path = os.path.join(\n",
        "                target_folder, f'{dataset_file_name}{dataset_part}.zip')\n",
        "            print(f'\\t\\tDownloading :  {path}')\n",
        "            download_file(url, path)\n",
        "            dataset_part += 1\n",
        "        except KeyboardInterrupt:\n",
        "            print('\\t\\t\\n\\nDownload stopped')\n",
        "            break\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7SwJGqBq3YE",
        "outputId": "88c0a044-1732-41c3-e82b-232c83053211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tDownloading dataset README.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1627/1627 [00:00<00:00, 210777.51B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tStarting download process\n",
            "\n",
            "\t\tDownloading :  dataset/brain_tumor_dataset_part_1.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 214401279/214401279 [00:09<00:00, 23645903.61B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tDownloading :  dataset/brain_tumor_dataset_part_2.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 217848429/217848429 [00:08<00:00, 25494023.09B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tDownloading :  dataset/brain_tumor_dataset_part_3.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 215563856/215563856 [00:10<00:00, 21021238.88B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tDownloading :  dataset/brain_tumor_dataset_part_4.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231679762/231679762 [00:11<00:00, 20883250.77B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzip Dataset"
      ],
      "metadata": {
        "id": "0lVW7sM5sIvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip_file(source_name, destination):\n",
        "    \"\"\" Unizips a zip file and stores the contents in destination folder.\n",
        "    Parameters:\n",
        "        source_name(str): Full path of the source path\n",
        "        destination(str): Full folder path where contents of source_name will be stored.\n",
        "\n",
        "    Returns: None\n",
        "    \"\"\"\n",
        "    with ZipFile(source_name, 'r') as zipfile:\n",
        "        # extracting all the files\n",
        "        print(f'\\tExtracting files of {source_name}')\n",
        "        zipfile.extractall(destination)\n",
        "        print(f'\\tDone with {source_name}')\n",
        "\n",
        "def main():\n",
        "    # Clears the screen.\n",
        "    clear_screen()\n",
        "\n",
        "    # File names in a list.\n",
        "    file_names = [\n",
        "        f'brain_tumor_dataset_part_{i}_done.zip' for i in range(1, 5)]\n",
        "\n",
        "    # Destination folder to store files.\n",
        "    destination = os.path.join('dataset', 'mat_dataset')\n",
        "    # Make the destination folder.\n",
        "    make_folder(os.path.join('dataset', 'mat_dataset'))\n",
        "\n",
        "    for file in file_names:\n",
        "        path = os.path.join('dataset', file)\n",
        "        unzip_file(path, destination)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V3_Q_5frzDE",
        "outputId": "1f20b7b7-98ae-44fb-8114-002a7c6b1e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating dataset/mat_dataset folder\n",
            "\tExtracting files of dataset/brain_tumor_dataset_part_1_done.zip\n",
            "\tDone with dataset/brain_tumor_dataset_part_1_done.zip\n",
            "\tExtracting files of dataset/brain_tumor_dataset_part_2_done.zip\n",
            "\tDone with dataset/brain_tumor_dataset_part_2_done.zip\n",
            "\tExtracting files of dataset/brain_tumor_dataset_part_3_done.zip\n",
            "\tDone with dataset/brain_tumor_dataset_part_3_done.zip\n",
            "\tExtracting files of dataset/brain_tumor_dataset_part_4_done.zip\n",
            "\tDone with dataset/brain_tumor_dataset_part_4_done.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract images"
      ],
      "metadata": {
        "id": "kf9m_EYqsOIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_data(filename, path):\n",
        "    \"\"\" Reads the mat image file and returns the image & mask array.\n",
        "    Parameters:\n",
        "        filename(str): Name of the file without the extension.\n",
        "        path(str): Path where the filename is located.\n",
        "\n",
        "    Returns:\n",
        "        data(dict): A dictionary with the image & mask numpy array.\n",
        "                    'image': The numpy array for image.\n",
        "                    'mask' : The numpy array for the above image mask.\n",
        "    \"\"\"\n",
        "    path = os.path.join(path, filename+'.mat')\n",
        "    file = h5py.File(path, 'r')\n",
        "    data = dict()\n",
        "    data['image'] = np.array(file.get('cjdata/image'))\n",
        "    data['mask'] = np.array(file.get('cjdata/tumorMask'))\n",
        "    return data\n",
        "\n",
        "\n",
        "def save_image_data(filename, path, data):\n",
        "    \"\"\" Saves the image & mask array in png format.\n",
        "    Parameters:\n",
        "        filename(str): Name of the file without the extension.\n",
        "        path(str): Path where the filename is to be saved.\n",
        "        data(dict): A dictionary with the image & mask numpy array.\n",
        "                    'image': The numpy array for image.\n",
        "                    'mask' : The numpy array for the above image mask.\n",
        "\n",
        "    Returns: None\n",
        "    \"\"\"\n",
        "    path_image = os.path.join(path, filename+'.png')\n",
        "    path_mask = os.path.join(path, filename+'_mask.png')\n",
        "    mpimg.imsave(path_image, data['image'], cmap='gray', format='png')\n",
        "    mpimg.imsave(path_mask, data['mask'], cmap='gray', format='png')\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Total number of images\n",
        "    total_images = 3064\n",
        "\n",
        "    # Dataset paths\n",
        "    data_read_path = os.path.join('dataset', 'mat_dataset')\n",
        "    data_save_path = os.path.join('dataset', 'png_dataset')\n",
        "\n",
        "    clear_screen()\n",
        "\n",
        "    # Make if folder is missing.\n",
        "    make_folder(data_save_path)\n",
        "\n",
        "    print(f'Starting to save images in {data_save_path}')\n",
        "\n",
        "    for filename in tqdm(range(1, total_images+1)):\n",
        "        filename = str(filename)\n",
        "        data = get_image_data(filename, data_read_path)\n",
        "        save_image_data(str(int(filename)-1), data_save_path, data)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo86fZ8qrSMQ",
        "outputId": "2fa5dd46-536c-48c0-c4c7-9919e7282fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating dataset/png_dataset folder\n",
            "Starting to save images in dataset/png_dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3064/3064 [05:54<00:00,  8.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organizar dataset en imagenes y labels\n"
      ],
      "metadata": {
        "id": "dXwQFM6hs0Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rutas de las carpetas original y destino\n",
        "input_folder = '/content/dataset/png_dataset'\n",
        "output_images_folder = '/content/dataset/imagenes'\n",
        "output_labels_folder = '/content/dataset/labels'\n",
        "\n",
        "# Crear las carpetas de salida si no existen\n",
        "os.makedirs(output_images_folder, exist_ok=True)\n",
        "os.makedirs(output_labels_folder, exist_ok=True)\n",
        "\n",
        "# Lista de archivos en la carpeta de entrada\n",
        "files = os.listdir(input_folder)\n",
        "\n",
        "# Iterar sobre los archivos y moverlos a las carpetas correspondientes\n",
        "for file in files:\n",
        "    if file.endswith('.png'):\n",
        "        if '_mask.png' in file:\n",
        "            file_name_without_mask = file.replace('_mask.png', '.png')\n",
        "            shutil.move(os.path.join(input_folder, file), os.path.join(output_labels_folder, file_name_without_mask))\n",
        "        else:\n",
        "            # Mover archivo a la carpeta de imágenes\n",
        "            shutil.move(os.path.join(input_folder, file), os.path.join(output_images_folder, file))"
      ],
      "metadata": {
        "id": "8DhlAfQityxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comprimir carpetas para descargar Dataset"
      ],
      "metadata": {
        "id": "1qcma0q03Uqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carpeta para contener las carpetas comprimidas\n",
        "output_dataset_folder = '/content/fmri_dataset'\n",
        "\n",
        "# Nombre del archivo ZIP de salida\n",
        "output_zip_file = '/content/fmri_dataset'\n",
        "\n",
        "shutil.rmtree(output_dataset_folder, ignore_errors=True)  # Elimina la carpeta si ya existe\n",
        "shutil.copytree(output_images_folder, output_dataset_folder + '/imagenes')\n",
        "shutil.copytree(output_labels_folder, output_dataset_folder + '/labels')\n",
        "\n",
        "# Comprimir las carpetas en un archivo ZIP\n",
        "shutil.make_archive(output_zip_file, 'zip', output_dataset_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FDHfwQt93-An",
        "outputId": "5d7e45a9-7336-48b5-a674-9a1a6f11fe1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/fmri_dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}